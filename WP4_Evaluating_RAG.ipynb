{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP4: Evaluating RAG\n",
    "\n",
    "* Put the contents of RAG_demo in here, along with any other relevant work - to make a single file people can run\n",
    "* **this will replace the rag_demo.ipynb and model_eval.ipynb files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "incl. Colab Specific Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running this notebook in colab please uncomment and run the following cell as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clone the github repo from the url below to access relevant files\n",
    "#!git clone https://github.com/nhsengland/ds_251_RAG\n",
    "#set working directory to the main repo folder\n",
    "#%cd ds_251_RAG\n",
    "#%pip install --upgrade --quiet anthropic transformers langchain_community bitsandbytes langchain accelerate tensorflow==2.15 chromadb unstructured sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant modules\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import toml\n",
    "\n",
    "\n",
    "import src.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "config = toml.load(\"config.toml\")\n",
    "\n",
    "if config['DEV_MODE']:\n",
    "    config['PERSIST_DIRECTORY'] += \"/dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise RAG Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline_phi2 = models.RagPipeline(config['EMBEDDING_MODEL'], config['PERSIST_DIRECTORY'], model_type='phi2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ANTHROPIC_API_KEY'] = \"\"\"*insert anthropic api key here*\"\"\"\n",
    "rag_pipeline_anthropic = models.RagPipeline(config['EMBEDDING_MODEL'], config['PERSIST_DIRECTORY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in documents into the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add documents if there are non - if in DEV mode, don't add any more (if it's not empty)\n",
    "if len(rag_pipeline_anthropic.vectorstore.get()['documents']) == 0 or (not config['DEV_MODE']):\n",
    "    rag_pipeline_anthropic.load_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Cogstack qns /answers\n",
    "\n",
    "link to cogstack QA data \"https://raw.githubusercontent.com/CogStack/OpenGPT/main/data/nhs_uk_full/prepared_generated_data_for_nhs_uk_qa.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load processed questions and answers\n",
    "cogstack_qa = pd.read_csv('src/model_eval/cogstack_qa_data_process.csv')\n",
    "\n",
    "#select a random sample of questions\n",
    "sample_qa = cogstack_qa.sample(n = 5, random_state = 999)\n",
    "sample_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples with RAG on and RAG off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Phi-2 Model with RAG off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = sample_qa['question'].values[0]\n",
    "result_rag_off_phi2 = rag_pipeline_phi2.llm('Instruction: {} \\n\\n Output:'.format(question))\n",
    "print(result_rag_off_phi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Phi-2 Model with RAG on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rag_on_phi2 = rag_pipeline_phi2.answer_question(question, model_type = 'phi2', rag=True)\n",
    "print(result_rag_on_phi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing anthropic model with RAG off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rag_off_anthropic = rag_pipeline_anthropic.answer_question(question, rag=False)\n",
    "print(result_rag_off_anthropic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing anthropic model with RAG on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rag_on_anthropic = rag_pipeline_anthropic.answer_question(question, rag=True)\n",
    "print(result_rag_on_anthropic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate responses for both models for each of the sample questions with RAG turned on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi2_responses = []\n",
    "phi2_references = []\n",
    "\n",
    "for index, row in sample_qa.iterrows():\n",
    "    #retrieve question answer and references from df\n",
    "    cogstack_q = row['question']\n",
    "    cogstack_a = row['answer']\n",
    "    cogstack_ref = row['short_reference']\n",
    "\n",
    "    #run question prompt through LLM and append result\n",
    "    result = rag_pipeline_phi2.answer_question(cogstack_q, rag=True)\n",
    "\n",
    "    #separate by word and extract reference and generated response\n",
    "    llm_result = result.split()[:-2]\n",
    "    if not llm_result:\n",
    "        llm_result = ''\n",
    "        llm_ref = ''\n",
    "    else:\n",
    "        llm_result = ' '.join(llm_result)\n",
    "        llm_ref = ' '.join(result.split()[-2:])\n",
    "\n",
    "    #append generated response and corresponding reference\n",
    "    phi2_responses.append(llm_result[llm_result.index('Output')+8:len(llm_result)])\n",
    "    phi2_references.append(llm_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_responses = []\n",
    "anthropic_references = []\n",
    "\n",
    "for index, row in sample_qa.iterrows():\n",
    "    #retrieve question answer and references from df\n",
    "    cogstack_q = row['question']\n",
    "    cogstack_a = row['answer']\n",
    "    cogstack_ref = row['short_reference']\n",
    "\n",
    "    #run question prompt through LLM and append result\n",
    "    result = rag_pipeline_anthropic.answer_question(cogstack_q, rag=True)\n",
    "\n",
    "    #separate by word and extract reference and generated response\n",
    "    llm_result = result.split()[:-2]\n",
    "    if not llm_result:\n",
    "        llm_result = ''\n",
    "        llm_ref = ''\n",
    "    else:\n",
    "        llm_result = ' '.join(llm_result)\n",
    "        llm_ref = ' '.join(result.split()[-2:])\n",
    "\n",
    "    #append generated response and corresponding reference\n",
    "    anthropic_responses.append(llm_result)\n",
    "    anthropic_references.append(llm_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the responses and references to the dataframe\n",
    "sample_qa['phi2_response'] = phi2_responses\n",
    "sample_qa['phi2_reference'] = phi2_references\n",
    "sample_qa['anthropic_response'] = anthropic_responses\n",
    "sample_qa['anthropic_reference'] = anthropic_references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
