{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG\n",
    "\n",
    "This work will look at the implementation of RAG within NHS England. This notebook contains a simple RAG pipeline which "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import toml\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "import src.models as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "config = toml.load(\"config.toml\")\n",
    "load_dotenv(\".secrets\")\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"anthropic_key\")\n",
    "\n",
    "if config['DEV_MODE']:\n",
    "    config['PERSIST_DIRECTORY'] += \"/dev\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = models.RagPipeline(config['EMBEDDING_MODEL'], config['PERSIST_DIRECTORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not config['DEV_MODE']):  # won't populate the database if in dev mode - we can just use what was already loaded.\n",
    "    rag_pipeline.load_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Explain the main benefits of Reproducible Analytical Pipelines (RAP)\"\n",
    "\n",
    "result = rag_pipeline.answer_question(question, rag=False)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline.retriever.get_relevant_documents(\"What is analytical best practice?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'markdown', 'text': 'some text'}]\n",
      "dict_keys(['mainEntityOfPage'])\n",
      "\n",
      "dict_keys(['name', 'text'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'some text'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text_from_html_json_chunk([{\"mainEntityOfPage\": [{\"name\": \"markdown\", \"text\": \"some text\"}]}]).getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line 45, in __main__.process_nhs_conditions_json\n",
      "Failed example:\n",
      "    process_nhs_conditions_json({\"html\": '{\"mainEntityOfPage\": [{\"name\": \"markdown\", \"text\": \"some text\"}]}'}).getvalue()\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"D:\\python3115\\Lib\\doctest.py\", line 1351, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.process_nhs_conditions_json[0]>\", line 1, in <module>\n",
      "        process_nhs_conditions_json({\"html\": '{\"mainEntityOfPage\": [{\"name\": \"markdown\", \"text\": \"some text\"}]}'}).getvalue()\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    AttributeError: 'str' object has no attribute 'getvalue'\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   1 of   1 in __main__.process_nhs_conditions_json\n",
      "***Test Failed*** 1 failures.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=1, attempted=2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "import io\n",
    "import src.data_ingestion.simple_nhs_conditions_scrape as simple_nhs_conditions_scrape\n",
    "\n",
    "\n",
    "def extract_text_from_html_json_chunk(ent: dict, text: str=None, key: str='mainEntityOfPage') -> io.StringIO:\n",
    "    \"\"\"Extracts text from the json object that contains the html for the nhs conditions pages\n",
    "    Args:\n",
    "    ent (dict): the json object\n",
    "    text (str, optional): the text to append to. Defaults to None.\n",
    "    key (str, optional): the key to look for in the json object. Defaults to \"mainEntityOfPage\".\n",
    "    Returns:\n",
    "    io.StringIO: the text extracted from the json object\n",
    "    \n",
    "    Example:\n",
    "    >>> extract_text_from_html_json_chunk([{\"mainEntityOfPage\": [{\"name\": \"markdown\", \"text\": \"some text\"}]}]).getvalue()\n",
    "    'some text'\n",
    "    \"\"\"   \n",
    "    if text is None:\n",
    "        text = io.StringIO()\n",
    "    for elt in ent:\n",
    "        nested = elt.get(key,\"\")\n",
    "        if key == \"mainEntityOfPage\":\n",
    "            if elt.get(\"name\") == \"markdown\":\n",
    "                text.write(elt.get('text'))\n",
    "        elif key == \"hasPart\":\n",
    "            headline_field = elt.get(\"headline\",\"\")\n",
    "            text_field = elt.get(\"text\",\"\")\n",
    "            description_field = elt.get(\"description\",\"\")\n",
    "            text.write(headline_field + \" \" + description_field + \" \" + text_field + \" \")\n",
    "\n",
    "        if isinstance(nested, list):\n",
    "            extract_text_from_html_json_chunk(nested, text, key = key)\n",
    "    return text\n",
    "\n",
    "\n",
    "def process_nhs_conditions_json(json_string: str) -> str:\n",
    "    \"\"\"Extracts the text from the json object that contains the html for the nhs conditions pages\n",
    "    Args:\n",
    "        json_string (str): the MHS Conditions json object (for a page), from the API.\n",
    "    Returns:\n",
    "        str: the text extracted from the json object\n",
    "    Example:\n",
    "    >>> process_nhs_conditions_json({\"html\": '{\"mainEntityOfPage\": [{\"name\": \"markdown\", \"text\": \"some text\"}]}'}).getvalue()\n",
    "    'some text'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = json.loads(obj['html'])\n",
    "\n",
    "        # there are currently two types of html structure in the nhs conditions data - one where the mainEntityOfPage holds the text, and one where the hasPart holds the text\n",
    "        main_entity_text = extract_text_from_html_json_chunk(content['mainEntityOfPage'], key='mainEntityOfPage').getvalue()\n",
    "        has_part_text = extract_text_from_html_json_chunk(content['hasPart'], key='hasPart').getvalue()\n",
    "        all_text = main_entity_text + has_part_text\n",
    "    except json.JSONDecodeError as e:\n",
    "        # some of the pages are just in HTML, not as a json object\n",
    "        print(\"Error decoding json for \", obj['source_url'])\n",
    "        all_text = \"\"\n",
    "    \n",
    "    return all_text\n",
    "\n",
    "import doctest\n",
    "doctest.testmod()\n",
    "\n",
    "\n",
    "# with jsonlines.open('nhsconditions.jsonl') as reader:\n",
    "#     for index, obj in enumerate(reader):\n",
    "#         extracted_text = process_nhs_conditions_json(obj)\n",
    "\n",
    "#         print(index, \": \", obj['source_url'] , \" === \", extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
